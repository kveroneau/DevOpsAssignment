Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.


------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

  # module.instances.aws_elb.backend_load_balancer will be created
  + resource "aws_elb" "backend_load_balancer" {
      + arn                         = (known after apply)
      + availability_zones          = (known after apply)
      + connection_draining         = false
      + connection_draining_timeout = 300
      + cross_zone_load_balancing   = true
      + dns_name                    = (known after apply)
      + id                          = (known after apply)
      + idle_timeout                = 60
      + instances                   = (known after apply)
      + internal                    = true
      + name                        = "veerum-Private-LoadBalance"
      + security_groups             = (known after apply)
      + source_security_group       = (known after apply)
      + source_security_group_id    = (known after apply)
      + subnets                     = (known after apply)
      + zone_id                     = (known after apply)

      + health_check {
          + healthy_threshold   = (known after apply)
          + interval            = (known after apply)
          + target              = (known after apply)
          + timeout             = (known after apply)
          + unhealthy_threshold = (known after apply)
        }

      + listener {
          + instance_port     = 80
          + instance_protocol = "HTTP"
          + lb_port           = 80
          + lb_protocol       = "HTTP"
        }
    }

  # module.instances.aws_elb.cluster_load_balancer will be created
  + resource "aws_elb" "cluster_load_balancer" {
      + arn                         = (known after apply)
      + availability_zones          = (known after apply)
      + connection_draining         = false
      + connection_draining_timeout = 300
      + cross_zone_load_balancing   = true
      + dns_name                    = (known after apply)
      + id                          = (known after apply)
      + idle_timeout                = 60
      + instances                   = (known after apply)
      + internal                    = false
      + name                        = "veerum-Public-LoadBalancer"
      + security_groups             = (known after apply)
      + source_security_group       = (known after apply)
      + source_security_group_id    = (known after apply)
      + subnets                     = (known after apply)
      + zone_id                     = (known after apply)

      + health_check {
          + healthy_threshold   = (known after apply)
          + interval            = (known after apply)
          + target              = (known after apply)
          + timeout             = (known after apply)
          + unhealthy_threshold = (known after apply)
        }

      + listener {
          + instance_port     = 80
          + instance_protocol = "HTTP"
          + lb_port           = 80
          + lb_protocol       = "HTTP"
        }
    }

  # module.instances.aws_security_group.elb_security_group will be created
  + resource "aws_security_group" "elb_security_group" {
      + arn                    = (known after apply)
      + description            = "ELB Security Group"
      + egress                 = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + id                     = (known after apply)
      + ingress                = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = "Allow web traffic to LB"
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + name                   = "veerum-ELB-SG"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + vpc_id                 = (known after apply)
    }

  # module.instances.aws_security_group.kubernetes_security_group will be created
  + resource "aws_security_group" "kubernetes_security_group" {
      + arn                    = (known after apply)
      + description            = "Kube pipe to nodes"
      + egress                 = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + id                     = (known after apply)
      + ingress                = (known after apply)
      + name                   = "veerum-Kubernetes-SG"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name" = "veerum-Kubernetes-SG"
        }
      + vpc_id                 = (known after apply)
    }

  # module.instances.aws_security_group.node_security_group will be created
  + resource "aws_security_group" "node_security_group" {
      + arn                    = (known after apply)
      + description            = "Nodes pipe to Kubernetes"
      + egress                 = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + id                     = (known after apply)
      + ingress                = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + name                   = "veerum-Node-SG"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name"                                = "veerum-Node-SG"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                 = (known after apply)
    }

  # module.instances.aws_security_group_rule.internal_kubernetes_https will be created
  + resource "aws_security_group_rule" "internal_kubernetes_https" {
      + cidr_blocks              = [
          + "0.0.0.0/0",
        ]
      + description              = "Internal pipe to Kubernetes"
      + from_port                = 443
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 443
      + type                     = "ingress"
    }

  # module.instances.aws_security_group_rule.kubernetes_nodes_https will be created
  + resource "aws_security_group_rule" "kubernetes_nodes_https" {
      + description              = "Nodes pipe to Kubernetes"
      + from_port                = 443
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 443
      + type                     = "ingress"
    }

  # module.instances.aws_security_group_rule.kubernetes_to_nodes will be created
  + resource "aws_security_group_rule" "kubernetes_to_nodes" {
      + description              = "Kubernetes pipe to Nodes"
      + from_port                = 1025
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 65535
      + type                     = "ingress"
    }

  # module.instances.aws_security_group_rule.node_to_node will be created
  + resource "aws_security_group_rule" "node_to_node" {
      + description              = "Nodes pipe to Nodes"
      + from_port                = 0
      + id                       = (known after apply)
      + protocol                 = "-1"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 65535
      + type                     = "ingress"
    }

  # module.kubernetes.aws_eks_cluster.eks_cluster will be created
  + resource "aws_eks_cluster" "eks_cluster" {
      + arn                   = (known after apply)
      + certificate_authority = (known after apply)
      + created_at            = (known after apply)
      + endpoint              = (known after apply)
      + id                    = (known after apply)
      + identity              = (known after apply)
      + name                  = "VeerumKluster"
      + platform_version      = (known after apply)
      + role_arn              = (known after apply)
      + status                = (known after apply)
      + version               = (known after apply)

      + vpc_config {
          + endpoint_private_access = false
          + endpoint_public_access  = true
          + security_group_ids      = (known after apply)
          + subnet_ids              = (known after apply)
          + vpc_id                  = (known after apply)
        }
    }

  # module.kubernetes.aws_iam_instance_profile.nodes_iam_instance_profile will be created
  + resource "aws_iam_instance_profile" "nodes_iam_instance_profile" {
      + arn         = (known after apply)
      + create_date = (known after apply)
      + id          = (known after apply)
      + name        = "veerum-Nodes-Profile"
      + path        = "/"
      + role        = "veerum-Node-Role"
      + roles       = (known after apply)
      + unique_id   = (known after apply)
    }

  # module.kubernetes.aws_iam_role.kubernetes_role will be created
  + resource "aws_iam_role" "kubernetes_role" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "eks.amazonaws.com"
                        }
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = false
      + id                    = (known after apply)
      + max_session_duration  = 3600
      + name                  = "veerum-Kubernetes-Role"
      + path                  = "/"
      + unique_id             = (known after apply)
    }

  # module.kubernetes.aws_iam_role.node_role will be created
  + resource "aws_iam_role" "node_role" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "ec2.amazonaws.com"
                        }
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = false
      + id                    = (known after apply)
      + max_session_duration  = 3600
      + name                  = "veerum-Node-Role"
      + path                  = "/"
      + unique_id             = (known after apply)
    }

  # module.kubernetes.aws_iam_role_policy.kubernetes_service_policy will be created
  + resource "aws_iam_role_policy" "kubernetes_service_policy" {
      + id     = (known after apply)
      + name   = "service-linked-role"
      + policy = jsonencode(
            {
              + Statement = [
                  + {
                      + Action   = "iam:CreateServiceLinkedRole"
                      + Effect   = "Allow"
                      + Resource = "arn:aws:iam::*:role/aws-service-role/*"
                    },
                  + {
                      + Action   = [
                          + "ec2:DescribeAccountAttributes",
                        ]
                      + Effect   = "Allow"
                      + Resource = "*"
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + role   = "veerum-Kubernetes-Role"
    }

  # module.kubernetes.aws_iam_role_policy_attachment.kubernetes_AwsEksClusterPolicy will be created
  + resource "aws_iam_role_policy_attachment" "kubernetes_AwsEksClusterPolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      + role       = "veerum-Kubernetes-Role"
    }

  # module.kubernetes.aws_iam_role_policy_attachment.kubernetes_AwsEksServicePolicy will be created
  + resource "aws_iam_role_policy_attachment" "kubernetes_AwsEksServicePolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      + role       = "veerum-Kubernetes-Role"
    }

  # module.kubernetes.aws_iam_role_policy_attachment.nodes_AwsEc2ContainerRegistryReadOnlyPolicy will be created
  + resource "aws_iam_role_policy_attachment" "nodes_AwsEc2ContainerRegistryReadOnlyPolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      + role       = "veerum-Node-Role"
    }

  # module.kubernetes.aws_iam_role_policy_attachment.nodes_AwsEksCniPolicy will be created
  + resource "aws_iam_role_policy_attachment" "nodes_AwsEksCniPolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      + role       = "veerum-Node-Role"
    }

  # module.kubernetes.aws_iam_role_policy_attachment.nodes_AwsEksWorkerNodePolicy will be created
  + resource "aws_iam_role_policy_attachment" "nodes_AwsEksWorkerNodePolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      + role       = "veerum-Node-Role"
    }

  # module.nodes.data.aws_ami.eks_node_ami will be read during apply
  # (config refers to values not yet known)
 <= data "aws_ami" "eks_node_ami"  {
      + architecture          = (known after apply)
      + block_device_mappings = (known after apply)
      + creation_date         = (known after apply)
      + description           = (known after apply)
      + hypervisor            = (known after apply)
      + id                    = (known after apply)
      + image_id              = (known after apply)
      + image_location        = (known after apply)
      + image_owner_alias     = (known after apply)
      + image_type            = (known after apply)
      + kernel_id             = (known after apply)
      + most_recent           = true
      + name                  = (known after apply)
      + owner_id              = (known after apply)
      + owners                = [
          + "602401143452",
        ]
      + platform              = (known after apply)
      + product_codes         = (known after apply)
      + public                = (known after apply)
      + ramdisk_id            = (known after apply)
      + root_device_name      = (known after apply)
      + root_device_type      = (known after apply)
      + root_snapshot_id      = (known after apply)
      + sriov_net_support     = (known after apply)
      + state                 = (known after apply)
      + state_reason          = (known after apply)
      + tags                  = (known after apply)
      + virtualization_type   = (known after apply)

      + filter {
          + name   = "name"
          + values = [
              + (known after apply),
            ]
        }
      + filter {
          + name   = "virtualization-type"
          + values = [
              + "hvm",
            ]
        }
    }

  # module.nodes.aws_autoscaling_group.eks_node will be created
  + resource "aws_autoscaling_group" "eks_node" {
      + arn                       = (known after apply)
      + availability_zones        = (known after apply)
      + default_cooldown          = (known after apply)
      + desired_capacity          = 2
      + force_delete              = false
      + health_check_grace_period = 300
      + health_check_type         = (known after apply)
      + id                        = (known after apply)
      + launch_configuration      = (known after apply)
      + load_balancers            = (known after apply)
      + max_size                  = 3
      + metrics_granularity       = "1Minute"
      + min_size                  = 1
      + name                      = "veerum-EKS-Node"
      + protect_from_scale_in     = false
      + service_linked_role_arn   = (known after apply)
      + target_group_arns         = (known after apply)
      + vpc_zone_identifier       = (known after apply)
      + wait_for_capacity_timeout = "10m"

      + tag {
          + key                 = "kubernetes.io/cluster/VeerumKluster"
          + propagate_at_launch = true
          + value               = "owned"
        }
    }

  # module.nodes.aws_launch_configuration.eks_node will be created
  + resource "aws_launch_configuration" "eks_node" {
      + associate_public_ip_address = true
      + ebs_optimized               = (known after apply)
      + enable_monitoring           = true
      + iam_instance_profile        = "veerum-Nodes-Profile"
      + id                          = (known after apply)
      + image_id                    = (known after apply)
      + instance_type               = "t2.micro"
      + key_name                    = "VeerumKey"
      + name                        = (known after apply)
      + name_prefix                 = "veerum_eks_node"
      + security_groups             = (known after apply)
      + user_data                   = (known after apply)

      + ebs_block_device {
          + delete_on_termination = (known after apply)
          + device_name           = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + no_device             = (known after apply)
          + snapshot_id           = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }

      + root_block_device {
          + delete_on_termination = (known after apply)
          + encrypted             = (known after apply)
          + iops                  = (known after apply)
          + volume_size           = (known after apply)
          + volume_type           = (known after apply)
        }
    }

  # module.setup.aws_key_pair.user_key will be created
  + resource "aws_key_pair" "user_key" {
      + fingerprint = (known after apply)
      + id          = (known after apply)
      + key_name    = "VeerumKey"
      + public_key  = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDvEzpg/U7ucCI+Mi/LfPY4vztyoEZS9iQU+sWQj7Ifva1ytFaf+P1XggPS1eLgEc4jPPKm/bb9oiDiMjLSsKWh+ytUk9h09pfLGnnwtqGwLYOZ2qIAKtlsRnEIQ7T0M95ZhtSkjnh/Sqw255QmHe55SOf9ACIUgEGtcjUOomc+KA5jalIPxWBbu8xBQhOlg3HFJG7yPFI109uHcPZMNztna/3X0crzucQRQKGXxu6hitoiRvnzSZnWbzZ6jM9NZlSJJe6oKD7PylGZMXkAJTl8A+ZTxzcy9yo9NIIjX/31DJwkVfG7LeCvz/Ya9ev+EMoQp+sNJo/6iI6iOfHnJPAz"
    }

  # module.vpc.aws_eip.elastic_ip_for_nat_gw will be created
  + resource "aws_eip" "elastic_ip_for_nat_gw" {
      + allocation_id     = (known after apply)
      + association_id    = (known after apply)
      + domain            = (known after apply)
      + id                = (known after apply)
      + instance          = (known after apply)
      + network_interface = (known after apply)
      + private_dns       = (known after apply)
      + private_ip        = (known after apply)
      + public_dns        = (known after apply)
      + public_ip         = (known after apply)
      + public_ipv4_pool  = (known after apply)
      + tags              = {
          + "Name" = "veerum-EIP"
        }
      + vpc               = true
    }

  # module.vpc.aws_internet_gateway.cluster will be created
  + resource "aws_internet_gateway" "cluster" {
      + id       = (known after apply)
      + owner_id = (known after apply)
      + tags     = {
          + "Name" = "veerum-IG"
        }
      + vpc_id   = (known after apply)
    }

  # module.vpc.aws_route_table.private_route_table will be created
  + resource "aws_route_table" "private_route_table" {
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = (known after apply)
      + tags             = {
          + "Name" = "veerum-Private-Route-Table"
        }
      + vpc_id           = (known after apply)
    }

  # module.vpc.aws_route_table.public_route_table will be created
  + resource "aws_route_table" "public_route_table" {
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = [
          + {
              + cidr_block                = "0.0.0.0/0"
              + egress_only_gateway_id    = ""
              + gateway_id                = (known after apply)
              + instance_id               = ""
              + ipv6_cidr_block           = ""
              + nat_gateway_id            = ""
              + network_interface_id      = ""
              + transit_gateway_id        = ""
              + vpc_peering_connection_id = ""
            },
        ]
      + tags             = {
          + "Name" = "veerum-Public-Route-Table"
        }
      + vpc_id           = (known after apply)
    }

  # module.vpc.aws_route_table_association.private_route_table-a-association will be created
  + resource "aws_route_table_association" "private_route_table-a-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.private_route_table-b-association will be created
  + resource "aws_route_table_association" "private_route_table-b-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.private_route_table-c-association will be created
  + resource "aws_route_table_association" "private_route_table-c-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public_route_table-a-association will be created
  + resource "aws_route_table_association" "public_route_table-a-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public_route_table-b-association will be created
  + resource "aws_route_table_association" "public_route_table-b-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_route_table_association.public_route_table-c-association will be created
  + resource "aws_route_table_association" "public_route_table-c-association" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.vpc.aws_subnet.private_subnet_aza will be created
  + resource "aws_subnet" "private_subnet_aza" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2a"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.4.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Private-Subnet-AZ_A"
          + "elb-int-key"                         = "elb-int-val"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.private_subnet_azb will be created
  + resource "aws_subnet" "private_subnet_azb" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2b"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.5.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Private-Subnet-AZ_B"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.private_subnet_azc will be created
  + resource "aws_subnet" "private_subnet_azc" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2c"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.6.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = false
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Private-Subnet-AZ_C"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public_subnet_aza will be created
  + resource "aws_subnet" "public_subnet_aza" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2a"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.1.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Public-Subnet-AZ_A"
          + "elb-key"                             = "elb-value"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public_subnet_azb will be created
  + resource "aws_subnet" "public_subnet_azb" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2b"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.2.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Public-Subnet-AZ_B"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_subnet.public_subnet_azc will be created
  + resource "aws_subnet" "public_subnet_azc" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = "us-west-2c"
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.3.0/24"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "Name"                                = "veerum-Public-Subnet-AZ_C"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_vpc.cluster_vpc will be created
  + resource "aws_vpc" "cluster_vpc" {
      + arn                              = (known after apply)
      + assign_generated_ipv6_cidr_block = false
      + cidr_block                       = "10.0.0.0/16"
      + default_network_acl_id           = (known after apply)
      + default_route_table_id           = (known after apply)
      + default_security_group_id        = (known after apply)
      + dhcp_options_id                  = (known after apply)
      + enable_classiclink               = (known after apply)
      + enable_classiclink_dns_support   = (known after apply)
      + enable_dns_hostnames             = true
      + enable_dns_support               = true
      + id                               = (known after apply)
      + instance_tenancy                 = "default"
      + ipv6_association_id              = (known after apply)
      + ipv6_cidr_block                  = (known after apply)
      + main_route_table_id              = (known after apply)
      + owner_id                         = (known after apply)
      + tags                             = {
          + "Name"                                = "veerum-VPC"
          + "kubernetes.io/cluster/VeerumKluster" = "owned"
        }
    }

Plan: 39 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

This plan was saved to: terraform.plan

To perform exactly these actions, run the following command to apply:
    terraform apply "terraform.plan"

